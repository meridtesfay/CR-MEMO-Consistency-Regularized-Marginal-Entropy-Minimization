# CR-MEMO-Consistency-Regularized-Marginal-Entropy-Minimization
CR-MEMO improves upon the original Marginal Entropy Minimization (MEMO) by introducing a consistency-regularization penalty. 
By penalizing the KL-divergence between individual augmented predictions and their marginal average, 
we ensure the model remains robust and semantically consistent under extreme distribution shifts.
